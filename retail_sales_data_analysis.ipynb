{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Sales Data Analysis\n",
    "\n",
    "In this project, we will be exploring and analyzing a historical retail sales dataset that details store-level performance, promotional activities, and seasonal effects over a defined period. The dataset includes information on various stores and their departments, featuring records of weekly sales, store characteristics, and a range of contextual factors such as regional conditions, holidays, and markdown events.\n",
    "\n",
    "By examining these data, we aim to gain insights into the relationships between promotional markdowns, holiday-driven consumer behavior, and overall sales outcomes across different stores and departments. This exploratory and analytical work will serve as a foundation for understanding the datasetâ€™s intricacies and will guide subsequent modeling and decision-making processes.\n",
    "\n",
    "The dataset can be found [here](https://www.kaggle.com/datasets/manjeetsingh/retaildataset 'Original Dataset from Manjeet Singh') on Kaggle.com by Manjeet Singh.\n",
    "\n",
    "First step is importing some libraries for use in Python. I also set the default theme for plots to Seaborn's default theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block of code, I use the Path function from pathlib to create some 'safe' relative file paths. I then use those file paths and Panda's read_csv function to create some DataFrames. Finally, the DataFrame's info is printed out so that we can get to know the data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data_file_path = Path('data/features_data_set.csv')\n",
    "sales_data_file_path = Path('data/sales_data_set.csv')\n",
    "stores_data_file_path = Path('data/stores_data_set.csv')\n",
    "\n",
    "features_df = pd.read_csv(features_data_file_path)\n",
    "sales_df = pd.read_csv(sales_data_file_path)\n",
    "stores_df = pd.read_csv(stores_data_file_path)\n",
    "\n",
    "print(features_df.info())\n",
    "print(sales_df.info())\n",
    "print(stores_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert some of the data types before we work with the datasets. After the conversions I will print out the data types again so that we can verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['Date'] = pd.to_datetime(features_df['Date'], format=\"%d/%m/%Y\")\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'], format=\"%d/%m/%Y\")\n",
    "stores_df[\"Type\"] = stores_df[\"Type\"].astype('string')\n",
    "\n",
    "print(features_df['Date'].info())\n",
    "print(sales_df['Date'].info())\n",
    "print(stores_df[\"Store\"].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and merge the tables so that we can have all of the information in one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables_merged_df = sales_df.merge(\n",
    "    features_df,\n",
    "    on=['Store', 'Date', 'IsHoliday'],\n",
    "    how='left'\n",
    "    ).merge(\n",
    "        stores_df,\n",
    "        on='Store',\n",
    "        how='left'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the merge worked by previewing our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take a look at the average weekly sales by store. First, we will use groupby to group the data according to the Store number.\n",
    "\n",
    "When we get the new DataFrame, the mean that is returned by the function is more precise than we really need it to be. We round the numbers so that they look more like regular currency values.\n",
    "\n",
    "Finally, we will merge the store_df table with the new table so that we can compare the different store types, sizes, and average weekly sales.\n",
    "\n",
    "After all of that, we preview our DataFrame to make sure everything has gone properly so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_department_df = all_tables_merged_df.groupby('Store').Weekly_Sales.mean().reset_index()\n",
    "\n",
    "grouped_by_department_df['Weekly_Sales'] = round(grouped_by_department_df['Weekly_Sales'], 2)\n",
    "\n",
    "avg_weekly_sales_by_store = pd.merge(\n",
    "    grouped_by_department_df,\n",
    "    stores_df,\n",
    "    on='Store',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weekly_sales_by_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(avg_weekly_sales_by_store, x=\"Store\", y=\"Weekly_Sales\",hue=\"Type\", kind='bar', aspect=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
