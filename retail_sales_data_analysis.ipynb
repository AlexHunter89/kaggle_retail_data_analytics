{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Sales Data Analysis\n",
    "\n",
    "In this project, we will be exploring and analyzing a historical retail sales dataset that details store-level performance, promotional activities, and seasonal effects over a defined period. The dataset includes information on various stores and their departments, featuring records of weekly sales, store characteristics, and a range of contextual factors such as regional conditions, holidays, and markdown events.\n",
    "\n",
    "By examining these data, we aim to gain insights into the relationships between promotional markdowns, holiday-driven consumer behavior, and overall sales outcomes across different stores and departments. This exploratory and analytical work will serve as a foundation for understanding the datasetâ€™s intricacies and will guide subsequent modeling and decision-making processes.\n",
    "\n",
    "The dataset can be found [here](https://www.kaggle.com/datasets/manjeetsingh/retaildataset 'Original Dataset from Manjeet Singh') on Kaggle.com by Manjeet Singh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are just importing some libraries for use in Python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We set the default theme for plots to Seaborn\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create path objects using pathlib\n",
    "\n",
    "features_data_file_path = Path('data/features_data_set.csv')\n",
    "sales_data_file_path = Path('data/sales_data_set.csv')\n",
    "stores_data_file_path = Path('data/stores_data_set.csv')\n",
    "\n",
    "# We use those file paths and Panda's read_csv to create DataFrames\n",
    "\n",
    "features_df = pd.read_csv(features_data_file_path)\n",
    "sales_df = pd.read_csv(sales_data_file_path)\n",
    "stores_df = pd.read_csv(stores_data_file_path)\n",
    "\n",
    "# Let's go ahead and view some informatin about our DataFrames\n",
    "\n",
    "print(features_df.info())\n",
    "print(sales_df.info())\n",
    "print(stores_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert some of the data types before we work with the datasets\n",
    "\n",
    "features_df['Date'] = pd.to_datetime(features_df['Date'], format=\"%d/%m/%Y\")\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'], format=\"%d/%m/%Y\")\n",
    "stores_df[\"Type\"] = stores_df[\"Type\"].astype('string')\n",
    "\n",
    "# We will print out the data types again so that we can verify the changes\n",
    "\n",
    "print(features_df['Date'].info())\n",
    "print(sales_df['Date'].info())\n",
    "print(stores_df[\"Store\"].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and merge the tables so that we can have all of the information in one DataFrame\n",
    "\n",
    "all_tables_merged_df = sales_df.merge(\n",
    "    features_df,\n",
    "    on=['Store', 'Date', 'IsHoliday'],\n",
    "    how='left'\n",
    "    ).merge(\n",
    "        stores_df,\n",
    "        on='Store',\n",
    "        how='left'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure the merge worked by previewing our DataFrame\n",
    "\n",
    "all_tables_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to take a look at the average weekly sales by store\n",
    "# First, we will use groupby to group the data according to the Store number\n",
    "\n",
    "grouped_by_department_df = all_tables_merged_df.groupby('Store').Weekly_Sales.mean().reset_index()\n",
    "\n",
    "# The mean that is returned by the function is more precise than we really need it to be\n",
    "# We round the numbers so that they look more like regular currency values\n",
    "\n",
    "grouped_by_department_df['Weekly_Sales'] = round(grouped_by_department_df['Weekly_Sales'], 2)\n",
    "\n",
    "# Finally, we will merge the store_df table with the new table so that we can compare the different\n",
    "# store types, sizes, and average weekly sales\n",
    "\n",
    "avg_weekly_sales_by_store = pd.merge(\n",
    "    grouped_by_department_df,\n",
    "    stores_df,\n",
    "    on='Store',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's preview our DataFrame to make sure everything has gone properly so far\n",
    "\n",
    "avg_weekly_sales_by_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(avg_weekly_sales_by_store, x=\"Store\", y=\"Weekly_Sales\",hue=\"Type\", kind='bar', aspect=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
